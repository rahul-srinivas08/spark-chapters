{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spark linear regression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dSPVYiXDMup",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d14c73b4-2a19-4364-ff13-88dbd8386bc6"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.6/dist-packages (3.0.0)\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.6/dist-packages (from pyspark) (0.10.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo35Y6V5GI5p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RoFH6QNGcRs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initialize SparkSession and SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkContext"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B2rfu7sG9eh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create a Spark Session\n",
        "SpSession = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1_30ZR3Ha47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get the Spark Context from Spark Session    \n",
        "SpContext = SpSession.sparkContext"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_LACjFfOuWC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df414edf-4fb7-4f0d-9759-5ef34c3255fd"
      },
      "source": [
        "#Load the CSV file into a RDD\n",
        "autoData = SpContext.textFile(\"/content/drive/My Drive/auto-miles-per-gallon.csv\")\n",
        "autoData.cache()\n",
        "autoData.take(5)\n",
        "#Remove the first line (contains headers)\n",
        "dataLines = autoData.filter(lambda x: \"CYLINDERS\" not in x)\n",
        "dataLines.count()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "398"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jy0Lp4QvPMrI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "aecdaa18-c0d4-478d-c02c-b5d98585f87e"
      },
      "source": [
        "#Cleanup Data\n",
        "\n",
        "from pyspark.sql import Row\n",
        "\n",
        "#Use default for average HP\n",
        "avgHP =SpContext.broadcast(80.0)\n",
        "\n",
        "#Function to cleanup Data\n",
        "def CleanupData( inputStr) :\n",
        "    global avgHP\n",
        "    attList=inputStr.split(\",\")\n",
        "    \n",
        "    #Replace ? values with a normal value\n",
        "    hpValue = attList[3]\n",
        "    if hpValue == \"?\":\n",
        "        hpValue=avgHP.value\n",
        "       \n",
        "    #Create a row with cleaned up and converted data\n",
        "    values= Row(     MPG=float(attList[0]),\\\n",
        "                     CYLINDERS=float(attList[1]), \\\n",
        "                     DISPLACEMENT=float(attList[2]), \n",
        "                     HORSEPOWER=float(hpValue),\\\n",
        "                     WEIGHT=float(attList[4]), \\\n",
        "                     ACCELERATION=float(attList[5]), \\\n",
        "                     MODELYEAR=float(attList[6]),\\\n",
        "                     NAME=attList[7]  ) \n",
        "    return values\n",
        "\n",
        "#Run map for cleanup\n",
        "autoMap = dataLines.map(CleanupData)\n",
        "autoMap.cache()\n",
        "autoMap.take(5)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(MPG=18.0, CYLINDERS=8.0, DISPLACEMENT=307.0, HORSEPOWER=130.0, WEIGHT=3504.0, ACCELERATION=12.0, MODELYEAR=70.0, NAME='chevrolet chevelle malibu'),\n",
              " Row(MPG=15.0, CYLINDERS=8.0, DISPLACEMENT=350.0, HORSEPOWER=165.0, WEIGHT=3693.0, ACCELERATION=11.5, MODELYEAR=70.0, NAME='buick skylark 320'),\n",
              " Row(MPG=18.0, CYLINDERS=8.0, DISPLACEMENT=318.0, HORSEPOWER=150.0, WEIGHT=3436.0, ACCELERATION=11.0, MODELYEAR=70.0, NAME='plymouth satellite'),\n",
              " Row(MPG=16.0, CYLINDERS=8.0, DISPLACEMENT=304.0, HORSEPOWER=150.0, WEIGHT=3433.0, ACCELERATION=12.0, MODELYEAR=70.0, NAME='amc rebel sst'),\n",
              " Row(MPG=17.0, CYLINDERS=8.0, DISPLACEMENT=302.0, HORSEPOWER=140.0, WEIGHT=3449.0, ACCELERATION=10.5, MODELYEAR=70.0, NAME='ford torino')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M62Otoa2Oxu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create a Data Frame with the data. \n",
        "autoDf = SpSession.createDataFrame(autoMap)\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDInTNNoHMTC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "38801713-15a7-4c3f-f431-9f1197f86738"
      },
      "source": [
        "#Perform Data Analytics\n",
        "#See descriptive analytics.\n",
        "autoDf.select(\"MPG\",\"CYLINDERS\").describe().show()\n",
        "\n",
        "\n",
        "#Find correlation between predictors and target\n",
        "from pyspark.mllib.stat import  Statistics\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----------------+------------------+\n",
            "|summary|              MPG|         CYLINDERS|\n",
            "+-------+-----------------+------------------+\n",
            "|  count|              398|               398|\n",
            "|   mean|23.51457286432161| 5.454773869346734|\n",
            "| stddev|7.815984312565782|1.7010042445332125|\n",
            "|    min|              9.0|               3.0|\n",
            "|    max|             46.6|               8.0|\n",
            "+-------+-----------------+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANRwMh_jHT1G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "5a9ff554-5364-4acc-e8a1-778f058973de"
      },
      "source": [
        "#Prepare data for ML\n",
        "\n",
        "\n",
        "#Transform to a Data Frame for input to Machine Learing\n",
        "#Drop columns that are not required (low correlation)\n",
        "\n",
        "from pyspark.ml.linalg import Vectors\n",
        "def transformToLabeledPoint(row) :\n",
        "    lp = ( row[\"MPG\"], Vectors.dense([row[\"ACCELERATION\"],\\\n",
        "                        row[\"DISPLACEMENT\"], \\\n",
        "                        row[\"WEIGHT\"]]))\n",
        "    return lp\n",
        "    \n",
        "autoLp = autoMap.map(transformToLabeledPoint)\n",
        "autoDF = SpSession.createDataFrame(autoLp,[\"label\", \"features\"])\n",
        "autoDF.select(\"label\",\"features\").show(10)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+-------------------+\n",
            "|label|           features|\n",
            "+-----+-------------------+\n",
            "| 18.0|[12.0,307.0,3504.0]|\n",
            "| 15.0|[11.5,350.0,3693.0]|\n",
            "| 18.0|[11.0,318.0,3436.0]|\n",
            "| 16.0|[12.0,304.0,3433.0]|\n",
            "| 17.0|[10.5,302.0,3449.0]|\n",
            "| 15.0|[10.0,429.0,4341.0]|\n",
            "| 14.0| [9.0,454.0,4354.0]|\n",
            "| 14.0| [8.5,440.0,4312.0]|\n",
            "| 14.0|[10.0,455.0,4425.0]|\n",
            "| 15.0| [8.5,390.0,3850.0]|\n",
            "+-----+-------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsBgnvyTIjQa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "76014881-0494-4b31-ee94-5404eaf63897"
      },
      "source": [
        "#Perform Machine Learning\n",
        "\n",
        "\n",
        "#Split into training and testing data\n",
        "(trainingData, testData) = autoDF.randomSplit([0.9, 0.1])\n",
        "trainingData.count()\n",
        "testData.count()\n",
        "\n",
        "#Build the model on training data\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "lr = LinearRegression(maxIter=10)\n",
        "lrModel = lr.fit(trainingData)\n",
        "\n",
        "#Print the metrics\n",
        "print(\"Coefficients: \" + str(lrModel.coefficients))\n",
        "print(\"Intercept: \" + str(lrModel.intercept))\n",
        "\n",
        "#Predict on the test data\n",
        "predictions = lrModel.transform(testData)\n",
        "predictions.select(\"prediction\",\"label\",\"features\").show()\n",
        "\n",
        "#Find R2 for Linear Regression\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
        "                 labelCol=\"label\",metricName=\"r2\")\n",
        "evaluator.evaluate(predictions)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Coefficients: [0.15725544298723257,-0.01159976712307584,-0.006149152249937106]\n",
            "Intercept: 41.57245247130714\n",
            "+------------------+-----+-------------------+\n",
            "|        prediction|label|           features|\n",
            "+------------------+-----+-------------------+\n",
            "|12.716503703465946| 13.0|[13.0,351.0,4363.0]|\n",
            "|14.741119669260655| 14.0|[13.0,318.0,4096.0]|\n",
            "|22.319969023487833| 15.0|[19.5,250.0,3158.0]|\n",
            "| 12.12039900522457| 16.0| [9.5,400.0,4278.0]|\n",
            "|23.520025902763713| 18.0|[14.5,171.0,2984.0]|\n",
            "|20.849824651053083| 19.0|[15.0,250.0,3282.0]|\n",
            "|23.478763930232535| 20.0|[16.0,232.0,2914.0]|\n",
            "| 26.03149473563134| 23.0|[15.0,115.0,2694.0]|\n",
            "| 28.39736756039587| 26.0|[12.5,121.0,2234.0]|\n",
            "|29.352758310511547| 26.0| [17.7,98.0,2255.0]|\n",
            "| 29.82897852614972| 26.0| [18.0,96.0,2189.0]|\n",
            "| 32.38731726297246| 26.0| [20.5,97.0,1835.0]|\n",
            "|29.629784691317617| 27.0| [14.5,97.0,2130.0]|\n",
            "|28.464263746521016| 28.0|[15.5,140.0,2264.0]|\n",
            "|  31.1435886086778| 29.5| [12.2,97.0,1825.0]|\n",
            "| 30.13387749167121| 30.0| [14.5,88.0,2065.0]|\n",
            "|16.995236029476445| 13.0|[14.0,318.0,3755.0]|\n",
            "|12.255978545543055| 15.5|[12.2,400.0,4325.0]|\n",
            "|14.580635780354488| 15.5|[13.7,318.0,4140.0]|\n",
            "| 20.17495756770381| 19.2|[19.2,231.0,3535.0]|\n",
            "+------------------+-----+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7049337311455797"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXQbLnmjKheU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}