{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spark DecisionTree regression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dSPVYiXDMup",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d14c73b4-2a19-4364-ff13-88dbd8386bc6"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.6/dist-packages (3.0.0)\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.6/dist-packages (from pyspark) (0.10.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo35Y6V5GI5p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RoFH6QNGcRs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initialize SparkSession and SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkContext"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B2rfu7sG9eh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create a Spark Session\n",
        "SpSession = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1_30ZR3Ha47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get the Spark Context from Spark Session    \n",
        "SpContext = SpSession.sparkContext"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_LACjFfOuWC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1be054fe-ae9d-4c73-d75a-7c8fd1039b32"
      },
      "source": [
        "#Load Data\n",
        "\n",
        "#Load the CSV file into a RDD\n",
        "irisData = SpContext.textFile(\"/content/drive/My Drive/iris.csv\")\n",
        "irisData.cache()\n",
        "irisData.count()\n",
        "\n",
        "#Remove the first line (contains headers)\n",
        "dataLines = irisData.filter(lambda x: \"Sepal\" not in x)\n",
        "dataLines.count()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jy0Lp4QvPMrI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "32bd342f-f7fa-4e1a-fe4e-5add9e033128"
      },
      "source": [
        "#Cleanup Data\n",
        "\n",
        "from pyspark.sql import Row\n",
        "#Create a Data Frame from the data\n",
        "parts = dataLines.map(lambda l: l.split(\",\"))\n",
        "irisMap = parts.map(lambda p: Row(SEPAL_LENGTH=float(p[0]),\\\n",
        "                                SEPAL_WIDTH=float(p[1]), \\\n",
        "                                PETAL_LENGTH=float(p[2]), \\\n",
        "                                PETAL_WIDTH=float(p[3]), \\\n",
        "                                SPECIES=p[4] ))\n",
        "                                \n",
        "# Infer the schema, and register the DataFrame as a table.\n",
        "irisDf = SpSession.createDataFrame(irisMap)\n",
        "irisDf.cache()\n",
        "\n",
        "#Add a numeric indexer for the label/target column\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "stringIndexer = StringIndexer(inputCol=\"SPECIES\", outputCol=\"IND_SPECIES\")\n",
        "si_model = stringIndexer.fit(irisDf)\n",
        "irisNormDf = si_model.transform(irisDf)\n",
        "\n",
        "irisNormDf.select(\"SPECIES\",\"IND_SPECIES\").distinct().show()\n",
        "irisNormDf.cache()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-----------+\n",
            "|   SPECIES|IND_SPECIES|\n",
            "+----------+-----------+\n",
            "|    setosa|        0.0|\n",
            "| virginica|        2.0|\n",
            "|versicolor|        1.0|\n",
            "+----------+-----------+\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[SEPAL_LENGTH: double, SEPAL_WIDTH: double, PETAL_LENGTH: double, PETAL_WIDTH: double, SPECIES: string, IND_SPECIES: double]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M62Otoa2Oxu4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "421a7a4e-9aea-4561-cb70-15814e0253cf"
      },
      "source": [
        "#Perform Data Analytics\n",
        "\n",
        "\n",
        "#See standard parameters\n",
        "irisNormDf.describe().show()\n",
        "\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------------------+------------------+------------------+------------------+---------+------------------+\n",
            "|summary|      SEPAL_LENGTH|       SEPAL_WIDTH|      PETAL_LENGTH|       PETAL_WIDTH|  SPECIES|       IND_SPECIES|\n",
            "+-------+------------------+------------------+------------------+------------------+---------+------------------+\n",
            "|  count|               150|               150|               150|               150|      150|               150|\n",
            "|   mean| 5.843333333333332|3.0573333333333337| 3.758000000000001|1.1993333333333331|     null|               1.0|\n",
            "| stddev|0.8280661279778634|0.4358662849366978|1.7652982332594662|0.7622376689603467|     null|0.8192319205190406|\n",
            "|    min|               4.3|               2.0|               1.0|               0.1|   setosa|               0.0|\n",
            "|    max|               7.9|               4.4|               6.9|               2.5|virginica|               2.0|\n",
            "+-------+------------------+------------------+------------------+------------------+---------+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDInTNNoHMTC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "b0dd7ae1-e29a-4312-8334-b816753e8383"
      },
      "source": [
        "\n",
        "#Prepare data for ML\n",
        "\n",
        "#Transform to a Data Frame for input to Machine Learing\n",
        "#Drop columns that are not required (low correlation)\n",
        "\n",
        "from pyspark.ml.linalg import Vectors\n",
        "def transformToLabeledPoint(row) :\n",
        "    lp = ( row[\"SPECIES\"], row[\"IND_SPECIES\"], \\\n",
        "                Vectors.dense([row[\"SEPAL_LENGTH\"],\\\n",
        "                        row[\"SEPAL_WIDTH\"], \\\n",
        "                        row[\"PETAL_LENGTH\"], \\\n",
        "                        row[\"PETAL_WIDTH\"]]))\n",
        "    return lp\n",
        "    \n",
        "irisLp = irisNormDf.rdd.map(transformToLabeledPoint)\n",
        "irisLpDf = SpSession.createDataFrame(irisLp,[\"species\",\"label\", \"features\"])\n",
        "irisLpDf.select(\"species\",\"label\",\"features\").show(10)\n",
        "irisLpDf.cache()\n",
        "\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----+-----------------+\n",
            "|species|label|         features|\n",
            "+-------+-----+-----------------+\n",
            "| setosa|  0.0|[5.1,3.5,1.4,0.2]|\n",
            "| setosa|  0.0|[4.9,3.0,1.4,0.2]|\n",
            "| setosa|  0.0|[4.7,3.2,1.3,0.2]|\n",
            "| setosa|  0.0|[4.6,3.1,1.5,0.2]|\n",
            "| setosa|  0.0|[5.0,3.6,1.4,0.2]|\n",
            "| setosa|  0.0|[5.4,3.9,1.7,0.4]|\n",
            "| setosa|  0.0|[4.6,3.4,1.4,0.3]|\n",
            "| setosa|  0.0|[5.0,3.4,1.5,0.2]|\n",
            "| setosa|  0.0|[4.4,2.9,1.4,0.2]|\n",
            "| setosa|  0.0|[4.9,3.1,1.5,0.1]|\n",
            "+-------+-----+-----------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[species: string, label: double, features: vector]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANRwMh_jHT1G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "5a9ff554-5364-4acc-e8a1-778f058973de"
      },
      "source": [
        "#Prepare data for ML\n",
        "\n",
        "\n",
        "#Transform to a Data Frame for input to Machine Learing\n",
        "#Drop columns that are not required (low correlation)\n",
        "\n",
        "from pyspark.ml.linalg import Vectors\n",
        "def transformToLabeledPoint(row) :\n",
        "    lp = ( row[\"MPG\"], Vectors.dense([row[\"ACCELERATION\"],\\\n",
        "                        row[\"DISPLACEMENT\"], \\\n",
        "                        row[\"WEIGHT\"]]))\n",
        "    return lp\n",
        "    \n",
        "autoLp = autoMap.map(transformToLabeledPoint)\n",
        "autoDF = SpSession.createDataFrame(autoLp,[\"label\", \"features\"])\n",
        "autoDF.select(\"label\",\"features\").show(10)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+-------------------+\n",
            "|label|           features|\n",
            "+-----+-------------------+\n",
            "| 18.0|[12.0,307.0,3504.0]|\n",
            "| 15.0|[11.5,350.0,3693.0]|\n",
            "| 18.0|[11.0,318.0,3436.0]|\n",
            "| 16.0|[12.0,304.0,3433.0]|\n",
            "| 17.0|[10.5,302.0,3449.0]|\n",
            "| 15.0|[10.0,429.0,4341.0]|\n",
            "| 14.0| [9.0,454.0,4354.0]|\n",
            "| 14.0| [8.5,440.0,4312.0]|\n",
            "| 14.0|[10.0,455.0,4425.0]|\n",
            "| 15.0| [8.5,390.0,3850.0]|\n",
            "+-----+-------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsBgnvyTIjQa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 756
        },
        "outputId": "ec73e262-029f-4898-fe6b-8bbe4be948d0"
      },
      "source": [
        "#Perform Machine Learning\n",
        "\n",
        "\n",
        "#Split into training and testing data\n",
        "(trainingData, testData) = irisLpDf.randomSplit([0.9, 0.1])\n",
        "trainingData.count()\n",
        "testData.count()\n",
        "testData.show()\n",
        "\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "#Create the model\n",
        "dtClassifer = DecisionTreeClassifier(maxDepth=2, labelCol=\"label\",\\\n",
        "                featuresCol=\"features\")\n",
        "dtModel = dtClassifer.fit(trainingData)\n",
        "\n",
        "dtModel.numNodes\n",
        "dtModel.depth\n",
        "\n",
        "#Predict on the test data\n",
        "predictions = dtModel.transform(testData)\n",
        "predictions.select(\"prediction\",\"species\",\"label\").show()\n",
        "\n",
        "#Evaluate accuracy\n",
        "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", \\\n",
        "                    labelCol=\"label\",metricName=\"accuracy\")\n",
        "evaluator.evaluate(predictions)      \n",
        "\n",
        "#Draw a confusion matrix\n",
        "predictions.groupBy(\"label\",\"prediction\").count().show()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-----+-----------------+\n",
            "|   species|label|         features|\n",
            "+----------+-----+-----------------+\n",
            "|    setosa|  0.0|[4.8,3.0,1.4,0.1]|\n",
            "|    setosa|  0.0|[5.0,3.4,1.5,0.2]|\n",
            "|    setosa|  0.0|[5.1,3.3,1.7,0.5]|\n",
            "|versicolor|  1.0|[5.2,2.7,3.9,1.4]|\n",
            "|versicolor|  1.0|[5.6,2.9,3.6,1.3]|\n",
            "|versicolor|  1.0|[7.0,3.2,4.7,1.4]|\n",
            "| virginica|  2.0|[6.4,3.2,5.3,2.3]|\n",
            "| virginica|  2.0|[6.5,3.0,5.5,1.8]|\n",
            "| virginica|  2.0|[6.7,2.5,5.8,1.8]|\n",
            "| virginica|  2.0|[6.7,3.0,5.2,2.3]|\n",
            "| virginica|  2.0|[6.7,3.3,5.7,2.1]|\n",
            "| virginica|  2.0|[6.7,3.3,5.7,2.5]|\n",
            "| virginica|  2.0|[6.8,3.2,5.9,2.3]|\n",
            "+----------+-----+-----------------+\n",
            "\n",
            "+----------+----------+-----+\n",
            "|prediction|   species|label|\n",
            "+----------+----------+-----+\n",
            "|       0.0|    setosa|  0.0|\n",
            "|       0.0|    setosa|  0.0|\n",
            "|       0.0|    setosa|  0.0|\n",
            "|       1.0|versicolor|  1.0|\n",
            "|       1.0|versicolor|  1.0|\n",
            "|       1.0|versicolor|  1.0|\n",
            "|       2.0| virginica|  2.0|\n",
            "|       2.0| virginica|  2.0|\n",
            "|       2.0| virginica|  2.0|\n",
            "|       2.0| virginica|  2.0|\n",
            "|       2.0| virginica|  2.0|\n",
            "|       2.0| virginica|  2.0|\n",
            "|       2.0| virginica|  2.0|\n",
            "+----------+----------+-----+\n",
            "\n",
            "+-----+----------+-----+\n",
            "|label|prediction|count|\n",
            "+-----+----------+-----+\n",
            "|  1.0|       1.0|    3|\n",
            "|  2.0|       2.0|    7|\n",
            "|  0.0|       0.0|    3|\n",
            "+-----+----------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXQbLnmjKheU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}